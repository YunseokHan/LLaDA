_wandb:
    value:
        cli_version: 0.19.6
        m: []
        python_version: 3.12.12
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 63
                - 71
                - 105
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 63
                - 71
                - 105
            "3":
                - 13
                - 15
                - 16
                - 23
                - 55
                - 61
            "4": 3.12.12
            "5": 0.19.6
            "6": 4.48.3
            "8":
                - 8
            "12": 0.19.6
            "13": linux-x86_64
batch_size:
    value: 4
block_eos:
    value: false
cfg_scale:
    value: 0
conv_block_length:
    value: 64
conv_mult:
    value: 1
conv_remask:
    value: low_confidence
conv_steps:
    value: 64
conv_temperature:
    value: 0
device:
    value: cuda
force_k1:
    value: true
gen_length:
    value: 256
halton_nb_points:
    value: 10000
halton_randomize:
    value: false
halton_sched_pow:
    value: 1
halton_steps:
    value: 64
halton_temp_max:
    value: 1
halton_temp_min:
    value: 1
halton_temp_pow:
    value: 1
halton_temp_warmup:
    value: 0
halton_top_k:
    value: -1
method:
    value: margin
mode:
    value: worker
model_name:
    value: GSAI-ML/LLaDA-8B-Instruct
"n":
    value: 100
num_shards:
    value: 8
num_steps:
    value: 256
semi_ar_block_size:
    value: 16
trial_shard:
    value: 6
trials_this_shard:
    value: 128
trials_total:
    value: 1024
